Наука о данных — это междисциплинарная область, которая объединяет статистику, вычислительные методы, научные подходы, обработку и визуализацию данных, а также алгоритмы и системы. Её цель — извлекать или прогнозировать знания и идеи из разнообразных данных, которые могут быть структурированными, неструктурированными или зашумлёнными.

Эта дисциплина также опирается на специализированные знания из прикладных областей, таких как естественные науки, информационные технологии и медицина. Наука о данных имеет множество аспектов и может рассматриваться как научная дисциплина, метод исследования, рабочий процесс, профессия и подход к решению задач.

Основные характеристики:
Применение теорий и методов из математики, статистики, компьютерных и информационных наук, а также предметных знаний.
Отличие от традиционных компьютерных и информационных наук.
Джим Грей, лауреат премии Тьюринга, охарактеризовал науку о данных как «четвёртую парадигму» науки, дополняющую эмпирический, теоретический и вычислительный подходы.
Роль специалиста по данным
Специалист по данным — это профессионал, который разрабатывает программное обеспечение и использует статистические знания для получения аналитических выводов, основанных на данных.

Основы науки о данных
Наука о данных сосредоточена на извлечении знаний из больших массивов данных и их применении для решения задач в различных сферах. Основные этапы её работы включают:

Подготовку данных для анализа.
Формулирование и постановку задач.
Анализ данных и разработку решений.
Представление результатов для поддержки управленческих решений.
Навыки и области
Для работы в этой области требуются знания из:

Компьютерных наук.
Статистики.
Математики.
Визуализации данных.
Коммуникации и понимания бизнес-процессов.
Связь со статистикой
Одни рассматривают науку о данных как расширение статистики, другие — как самостоятельную дисциплину, ориентированную на работу с цифровыми данными. Васант Дхар подчёркивает, что наука о данных сочетает работу с количественными и качественными данными, акцентируя внимание на прогнозировании и принятии решений.

Историческая справка и этимология
1962 год: Джон Тьюки ввёл понятие «анализ данных», обозначив новый подход к исследованию данных.
1974 год: Питер Наур предложил термин «наука о данных» как альтернативу «компьютерной науке».
1985 год: К. Ф. Джефф Ву впервые официально использовал термин «наука о данных» в академическом контексте.
2001 год: Уильям С. Кливленд расширил концепцию статистики, включив в неё технические аспекты, что обосновало применение термина «наука о данных».
Современное развитие
2012 год: Томас Дэвенпорт и Ди Джей Патил охарактеризовали профессию специалиста по данным как «самую сексуальную профессию 21 века».
2014 год: Секция Американской статистической ассоциации по статистическому обучению и анализу данных была переименована в Секцию по статистическому обучению и науке о данных, что отразило значимость дисциплины.
Отличия между наукой о данных и анализом данных
Наука о данных:

Является междисциплинарной областью, объединяющей статистику, вычислительные методы, машинное обучение и работу с неструктурированными данными.
Включает предварительную обработку данных, построение моделей и разработку алгоритмов для решения задач прогнозирования или выявления закономерностей.
Анализ данных:

Фокусируется на работе с структурированными данными.
Основными задачами являются очистка данных, визуализация и исследовательский анализ для извлечения значений из данных.
Роль облачных технологий в науке о данных
Облачные вычисления предоставляют значительные преимущества для обработки больших объёмов данных:

Доступ к масштабируемым вычислительным ресурсам и облачным хранилищам.
Сокращение времени на обработку больших массивов информации.
Удобство внедрения и тестирования сложных аналитических моделей без необходимости закупки дорогого оборудования.
Этические аспекты в науке о данных
Конфиденциальность данных: Процессы сбора, обработки и анализа часто связаны с персональными данными, что требует соблюдения этических и правовых норм.
Предвзятость данных: Использование исторических данных в моделях машинного обучения может приводить к усилению системных предрассудков, создавая несправедливые или дискриминационные выводы.
Роль науки о данных
Наука о данных объединяет статистику, вычислительные технологии и методы машинного обучения для извлечения знаний из данных. Специалисты в этой области преобразуют необработанные данные в полезные инсайты, которые помогают организациям принимать обоснованные стратегические и операционные решения. Работа охватывает обработку структурированных (например, реляционные базы данных) и неструктурированных данных (например, текстовые данные, изображения, аудио), что требует владения сложными методами анализа, моделирования и прогнозирования.

Основные этапы работы специалиста по данным
Сбор данных: Получение информации из различных источников, таких как базы данных, API или методы веб-скрапинга.
Очистка данных: Приведение данных в пригодный для анализа вид, включая устранение ошибок, удаление пропущенных значений и устранение дубликатов.
Анализ данных: Применение статистических и визуальных методов для первичного изучения данных и поиска закономерностей.
Моделирование: Создание и обучение моделей машинного обучения для прогнозирования и анализа.
Интерпретация результатов: Объяснение полученных данных и выводов для поддержки принятия решений.
Применение науки о данных
Наука о данных востребована в самых разных отраслях:

Финансы: Анализ финансовых рисков и прогнозирование доходности.
Маркетинг: Разработка персонализированных маркетинговых стратегий.
Здравоохранение: Создание алгоритмов диагностики и прогнозирования заболеваний.
Ритейл: Построение рекомендательных систем для онлайн-покупателей.
Производство: Оптимизация процессов и прогнозирование спроса.
Современные технологии, такие как облачные вычисления и анализ больших данных (Big Data), позволяют обрабатывать огромные объемы информации в реальном времени, что особенно важно при работе с потоковыми данными.

Этические аспекты
Важной частью работы специалистов по данным является соблюдение этических принципов:

Обеспечение конфиденциальности и безопасности данных.
Предотвращение использования предвзятых данных, которые могут повлиять на справедливость алгоритмов.
Устранение ошибок, которые могут привести к дискриминации или несправедливым выводам.
Большие данные: определение и вызовы
Большие данные — это массивы данных, которые по своему объему, сложности или скорости обработки превышают возможности традиционных инструментов. Их характерными чертами являются:

Объем: Огромное количество информации.
Разнообразие: Разные форматы данных (структурированные, неструктурированные, мультимедийные).
Скорость: Высокая частота поступления данных в режиме реального времени.
Достоверность: Качество и точность данных.
Основные трудности работы с большими данными включают:

Сбор, хранение и обработку.
Анализ и визуализацию.
Обеспечение безопасности и конфиденциальности.
Использование и вызовы больших данных
Большие данные часто применяются для создания прогнозов и решения сложных задач в таких областях, как:

Здравоохранение: Анализ геномных данных и прогнозирование эпидемий.
Финансовые технологии: Выявление мошеннических операций.
Геоинформационные системы: Улучшение картографии и транспортной логистики.
Объем данных продолжает расти. Например, в 2012 году ежедневно создавалось 2,5 эксабайта данных, а к 2025 году прогнозируется увеличение до 163 зеттабайт. Однако без достаточной экспертизы управление такими массивами может быть экономически неэффективным.

Технологии обработки больших данных
Для работы с большими данными применяются системы, способные выполнять массово параллельные вычисления. С увеличением объёмов информации, от гигабайт до терабайт и более, подходы к управлению данными также должны адаптироваться.

Определение
Термин «большие данные» появился в 1990-х годах и относится к массивам данных, которые невозможно обработать с помощью традиционных инструментов. Они включают как структурированную, так и неструктурированную информацию, при этом основное внимание уделяется последней. Методы и технологии обработки данных постоянно совершенствуются для решения новых задач.

Основные характеристики
В 2018 году большие данные определялись как область, требующая применения инструментов параллельных вычислений для обработки информации. К их ключевым характеристикам относят:

Объём (Volume)
Разнообразие (Variety)
Скорость (Velocity)
Достоверность (Veracity)
Ценность (Value)
Изменчивость (Variability)
Сравнение с бизнес-аналитикой
Бизнес-аналитика использует описательную статистику для измерения показателей и анализа тенденций, тогда как большие данные применяют сложные математические и статистические методы для поиска закономерностей и построения прогнозов.

Характеристики больших данных
Объём (Volume)

Отражает количество создаваемых и хранимых данных.
Большие данные, как правило, измеряются в терабайтах и петабайтах.
Разнообразие (Variety)

Типы данных включают структурированные, полуструктурированные и неструктурированные.
Источники данных могут быть текстовыми, графическими, аудио- или видеоматериалами.
Скорость (Velocity)

Описывает скорость создания и обработки данных.
Часто данные обрабатываются в режиме реального времени.
Достоверность (Veracity)

Качество и надёжность данных, которые могут варьироваться в зависимости от источника.
Ценность (Value)

Способность извлекать из данных полезную информацию для принятия решений.
Изменчивость (Variability)

Флуктуации в формате или структуре данных, что может усложнять их обработку.

Надёжность и качество данных
Надёжность данных

Влияет на точность анализа и построение выводов.
Ценность данных

Оценивается по полезности и прибыли, которую можно извлечь из анализа.
Основной результат — информация и инсайты, влияющие на принятие решений.
Изменчивость данных

Отражает изменения форматов и источников данных.
Учитывает необходимость интеграции структурированной и неструктурированной информации.
Дополнительные характеристики данных
Полнота: Учитывает, охватывают ли данные весь необходимый объём информации.
Детализация и уникальность: Возможность индексирования и наличие уникальных элементов данных.
Относительность: Способность объединять данные из разных источников и наборов.
Расширяемость: Лёгкость добавления новых данных в существующую инфраструктуру.
Масштабируемость: Возможность увеличивать объёмы хранимой информации без потери производительности.
Архитектура и технологии для обработки больших данных
Исторические примеры:
Teradata
Первая система параллельной обработки терабайтных данных (с 1984 года).
HPCC Systems
Платформа на C++, поддерживающая работу со структурированными и неструктурированными данными.
MapReduce (Google, 2004)
Параллельная обработка данных с использованием этапов map (разделение задач) и reduce (объединение результатов).
Hadoop и Apache Spark
Современные системы, включающие распределённую обработку данных и обработку в оперативной памяти.
Методы анализа:
A/B-тестирование.
Алгоритмы машинного обучения.
Методы обработки естественного языка (NLP).
Хранилища данных:
Облачные решения.
Распределённые базы данных.
Параллельные СУБД.
Озёра данных (Data Lakes), обеспечивающие гибкую работу с разными типами данных.
Технологии с поддержкой массово параллельной обработки (MPP).
Визуализация данных:
Создание графиков, диаграмм и других методов отображения информации для её анализа и представления.
Проблемы и подходы к решению
Многослойная архитектура
Обеспечивает распределение данных для повышения скорости обработки.
Озёра данных
Позволяют упрощать работу с данными, минимизировать затраты и ускорять анализ.
Производительность
Использование систем прямого подключения (DAS) вместо более медленных SAN и NAS для повышения производительности.
Современные подходы и технологии
Обработка в реальном времени
Уменьшение задержек для своевременной аналитики.
Инфраструктура
Применение SSD-дисков и параллельных узлов для ускорения обработки.
Отказ от сложных и дорогостоящих SAN в пользу более экономичных решений.