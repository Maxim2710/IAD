{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from dsmltf import scale, KMeans, generate_clusters, get_children, distance, is_leaf, squared_distance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# def load_and_process_data(file_path: str) -> list:\n",
    "#     \"\"\"\n",
    "#     Загружает данные из CSV файла, обрабатывает их и возвращает список выбранных колонок.\n",
    "#\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     file_path : str\n",
    "#         Путь к CSV файлу, содержащему данные.\n",
    "#\n",
    "#     Returns\n",
    "#     -------\n",
    "#     list\n",
    "#         Список обработанных данных, включающий закодированные жанры, продолжительность, IMDB рейтинг и язык.\n",
    "#     \"\"\"\n",
    "#     data = []  # Список для хранения обработанных данных\n",
    "#     genre_map = {}  # Словарь для хранения уникальных жанров и их индексов\n",
    "#     language_map = {}  # Словарь для хранения уникальных языков и их индексов\n",
    "#     genre_index = 0  # Индекс для жанров\n",
    "#     language_index = 0  # Индекс для языков\n",
    "#\n",
    "#     # Открываем CSV файл и начинаем читать его\n",
    "#     with open(file_path, \"r\", encoding=\"UTF-8\") as f:\n",
    "#         reader = csv.reader(f)  # Используем csv.reader для чтения файла\n",
    "#         headers = next(reader)  # Пропускаем строку с заголовками\n",
    "#\n",
    "#         # Проходим по всем строкам данных\n",
    "#         for row in reader:\n",
    "#             genre = row[1]  # Извлекаем жанр из строки\n",
    "#             if genre not in genre_map:\n",
    "#                 genre_map[genre] = genre_index  # Если жанр новый, добавляем его в словарь\n",
    "#                 genre_index += 1  # Увеличиваем индекс для следующего жанра\n",
    "#\n",
    "#             language = row[5]  # Извлекаем язык из строки\n",
    "#             if language not in language_map:\n",
    "#                 language_map[language] = language_index  # Если язык новый, добавляем его в словарь\n",
    "#                 language_index += 1  # Увеличиваем индекс для следующего языка\n",
    "#\n",
    "#             # Кодируем жанр и язык в числа, а также сохраняем продолжительность и IMDB рейтинг\n",
    "#             genre_encoded = genre_map[genre]\n",
    "#             runtime = int(row[3])  # Продолжительность\n",
    "#             imdb_score = float(row[4])  # IMDB рейтинг\n",
    "#             language_encoded = language_map[language]\n",
    "#\n",
    "#             # Добавляем обработанные данные в список\n",
    "#             data.append([genre_encoded, runtime, imdb_score, language_encoded])\n",
    "#\n",
    "#     return data  # Возвращаем список обработанных данных\n",
    "\n",
    "def load_and_process_data(file_path: str) -> list:\n",
    "    \"\"\"\n",
    "    Загружает данные из CSV файла, обрабатывает их и возвращает список с продолжительностью и рейтингом IMDB.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        Путь к CSV файлу, содержащему данные.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Список обработанных данных, включающий продолжительность и IMDB рейтинг.\n",
    "    \"\"\"\n",
    "    data = []  # Список для хранения обработанных данных\n",
    "\n",
    "    # Открываем CSV файл и начинаем читать его\n",
    "    with open(file_path, \"r\", encoding=\"UTF-8\") as f:\n",
    "        reader = csv.reader(f)  # Используем csv.reader для чтения файла\n",
    "        headers = next(reader)  # Пропускаем строку с заголовками\n",
    "\n",
    "        # Проходим по всем строкам данных\n",
    "        for row in reader:\n",
    "            runtime = int(row[3])  # Извлекаем продолжительность\n",
    "            imdb_score = float(row[4])  # Извлекаем IMDB рейтинг\n",
    "            # Добавляем обработанные данные в список\n",
    "            data.append([runtime, imdb_score])\n",
    "\n",
    "    return data  # Возвращаем список обработанных данных\n",
    "\n",
    "def squared_errors(inps, k):\n",
    "    \"\"\"\n",
    "    Вычисляет сумму квадратов ошибок для заданного количества кластеров.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    inps : list\n",
    "        Список данных для кластеризации.\n",
    "    k : int\n",
    "        Количество кластеров.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Сумма квадратов ошибок.\n",
    "    \"\"\"\n",
    "    clasterbuilder = KMeans(k)\n",
    "    clasterbuilder.train(inps)\n",
    "    means = clasterbuilder.means\n",
    "    inclaster = map(clasterbuilder.classify, inps)\n",
    "    return sum(squared_distance(inp, means[cluster])\n",
    "               for inp, cluster in zip(inps, inclaster))\n",
    "\n",
    "def plot_squared_errors(x, y):\n",
    "    \"\"\"\n",
    "    Строит график зависимости квадратных ошибок от числа кластеров.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : list\n",
    "        Список значений количества кластеров.\n",
    "    y : list\n",
    "        Список значений квадратных ошибок.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        График не возвращает значений, а только отображается.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))  # Настроим размер графика\n",
    "    plt.plot(x, y, label='Squared Error vs Number of Clusters', marker='o', color='b')  # Строим график\n",
    "    plt.title('Squared Error for Different Numbers of Clusters', fontsize=16)  # Заголовок графика\n",
    "    plt.xlabel('Number of Clusters (k)', fontsize=12)  # Метка оси X\n",
    "    plt.ylabel('Squared Error', fontsize=12)  # Метка оси Y\n",
    "    plt.grid(True)  # Включаем сетку для удобства чтения графика\n",
    "    plt.legend()  # Добавляем легенду\n",
    "    plt.show()  # Отображаем график\n",
    "\n",
    "def plot_clusters(data, kmeans, xlim=None, ylim=None):\n",
    "    \"\"\"\n",
    "    Визуализирует точки данных с их кластерами.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : list\n",
    "        Список данных для визуализации.\n",
    "    kmeans : KMeans\n",
    "        Обученная модель KMeans.\n",
    "    xlim : tuple, optional\n",
    "        Лимиты для оси X (min, max).\n",
    "    ylim : tuple, optional\n",
    "        Лимиты для оси Y (min, max).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        График не возвращает значений, а только отображается.\n",
    "    \"\"\"\n",
    "    # Получаем предсказания кластеров для каждого элемента данных\n",
    "    clusters = [kmeans.classify(point) for point in data]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))  # Устанавливаем размер графика\n",
    "    for i, cluster in enumerate(set(clusters)):\n",
    "        # Отбираем точки, принадлежащие текущему кластеру\n",
    "        cluster_points = [point for j, point in enumerate(data) if clusters[j] == cluster]\n",
    "        cluster_points = list(zip(*cluster_points))  # Разделяем координаты для удобства\n",
    "\n",
    "        # Рисуем точки, относящиеся к текущему кластеру\n",
    "        plt.scatter(cluster_points[0], cluster_points[1], label=f\"Cluster {i + 1}\", s=50)\n",
    "\n",
    "    # Устанавливаем лимиты осей, если они заданы\n",
    "    if xlim:\n",
    "        plt.xlim(xlim)\n",
    "    if ylim:\n",
    "        plt.ylim(ylim)\n",
    "\n",
    "    # Добавляем подписи осей и легенду\n",
    "    plt.title(\"Cluster Visualization\", fontsize=16)\n",
    "    plt.xlabel(\"Scaled Runtime\", fontsize=12)\n",
    "    plt.ylabel(\"Scaled IMDB Score\", fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def train_kmeans_model(data, k):\n",
    "    \"\"\"\n",
    "    Обучает модель KMeans с заданным количеством кластеров.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : list\n",
    "        Список данных для кластеризации.\n",
    "    k : int\n",
    "        Количество кластеров.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    KMeans\n",
    "        Обученная модель KMeans.\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(k)  # Создаем модель KMeans с k кластерами\n",
    "    kmeans.train(data)  # Обучаем модель на данных\n",
    "    return kmeans  # Возвращаем обученную модель\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Основная функция для кластеризации данных и отображения графика.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Выполняет кластеризацию, строит график и выводит результаты.\n",
    "    \"\"\"\n",
    "    data_set = load_and_process_data(\"../data/NetflixOriginals.csv\")  # Загружаем и обрабатываем данные из файла\n",
    "    scaled_data = scale(data_set[:100])  # Масштабируем данные (используем только первые 100 строк)\n",
    "\n",
    "    # scaled_data = scale(data_set)\n",
    "    # x = []\n",
    "    # y = []\n",
    "    # for k in range(1, 20):\n",
    "    #     x.append(k)\n",
    "    #     y.append(squared_errors(scaled_data, k))\n",
    "    # print(x)\n",
    "    # print(y)\n",
    "\n",
    "    # Предварительно вычисленные квадраты ошибок для разных значений k\n",
    "    x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
    "    y = [2335.999999999999, 2121.8352144649193, 1733.7098159551483, 1731.3833543466562, 1280.8200011472968,\n",
    "         1322.1644570532922, 1252.6341500009034, 1298.8260055309267, 947.215995282551, 1128.3021378553422,\n",
    "         1069.8306918750236, 743.2111211305224, 793.3788479920217, 918.4788661897383, 694.7464225286514,\n",
    "         793.8435582134562, 1007.5325400497563, 694.594807606682, 696.2283658958489]\n",
    "\n",
    "    plot_squared_errors(x, y)  # Строим график зависимости квадратных ошибок от числа кластеров\n",
    "\n",
    "    optimal_k = 7\n",
    "\n",
    "    kmeans = train_kmeans_model(scaled_data, optimal_k)  # Обучаем модель KMeans с 9 кластерами\n",
    "    print(kmeans.means)  # Выводим центры кластеров\n",
    "\n",
    "    # Иерархическая кластеризация\n",
    "    base_cluster = bottom_up_cluster(scaled_data)  # Строим иерархическую кластеризацию\n",
    "    print([get_values(cluster) for cluster in generate_clusters(base_cluster, optimal_k)])  # Выводим кластеры\n",
    "\n",
    "    plot_clusters(scaled_data, kmeans, xlim=(-6, 4), ylim=(-5, 3))\n",
    "\n",
    "def bottom_up_cluster(inputs, distance_agg=min):\n",
    "    \"\"\"\n",
    "    Выполняет иерархическую кластеризацию данных методом \"снизу-вверх\".\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    inputs : list\n",
    "        Список данных для кластеризации.\n",
    "    distance_agg : function, optional\n",
    "        Функция для агрегации расстояний (по умолчанию используется минимальное расстояние).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Иерархически скомпонованный кластер.\n",
    "    \"\"\"\n",
    "    clusters = [(inp,) for inp in inputs]  # Создаем начальные кластеры (каждое значение в отдельном кластере)\n",
    "    while len(clusters) > 1:  # Пока в списке кластеров больше одного\n",
    "        # Находим пару кластеров с минимальным расстоянием\n",
    "        c1, c2 = min([(cluster1, cluster2)\n",
    "                      for i, cluster1 in enumerate(clusters)\n",
    "                      for cluster2 in clusters[:i]],\n",
    "                     key=lambda x: cluster_distance(*x, distance_agg))\n",
    "        clusters = [c for c in clusters if c != c1 and c != c2]  # Удаляем эти два кластера из списка\n",
    "        merged_cluster = (len(clusters), [c1, c2])  # Объединяем два кластера в один\n",
    "        clusters.append(merged_cluster)  # Добавляем новый объединенный кластер в список\n",
    "\n",
    "    return clusters[0]  # Возвращаем финальный кластер\n",
    "\n",
    "\n",
    "def get_values(cluster):\n",
    "    \"\"\"\n",
    "    Извлекает значения из кластера.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cluster : tuple\n",
    "        Кластер, из которого необходимо извлечь значения.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Список значений из кластера.\n",
    "    \"\"\"\n",
    "    if is_leaf(cluster):  # Если кластер является \"листьем\" (он не содержит другие кластеры)\n",
    "        return [cluster[0]]  # Возвращаем сам элемент\n",
    "    else:\n",
    "        # Рекурсивно извлекаем значения из всех вложенных кластеров\n",
    "        return [val for child in get_children(cluster) for val in get_values(child)]\n",
    "\n",
    "\n",
    "def cluster_distance(cluster1, cluster2, distance_agg=min):\n",
    "    \"\"\"\n",
    "    Вычисляет расстояние между двумя кластерами.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cluster1 : tuple\n",
    "        Первый кластер.\n",
    "    cluster2 : tuple\n",
    "        Второй кластер.\n",
    "    distance_agg : function, optional\n",
    "        Функция для агрегации расстояний (по умолчанию используется минимальное расстояние).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Расстояние между двумя кластерами.\n",
    "    \"\"\"\n",
    "    values1 = list(get_values(cluster1))  # Извлекаем все значения из первого кластера\n",
    "    values2 = list(get_values(cluster2))  # Извлекаем все значения из второго кластера\n",
    "    # Вычисляем расстояние между всеми парами значений из двух кластеров и агрегация их с помощью distance_agg\n",
    "    return distance_agg([distance(list(inp1), list(inp2)) for inp1 in values1 for inp2 in values2])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()  # Запускаем основную функцию\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e7c336d636355025"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
